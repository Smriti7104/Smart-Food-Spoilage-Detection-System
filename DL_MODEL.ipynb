{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31ca281d",
   "metadata": {},
   "source": [
    "Deep Learning Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6ac602d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello\n"
     ]
    }
   ],
   "source": [
    "print(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e95ec6cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid decimal literal (2549014608.py, line 39)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[5], line 39\u001b[1;36m\u001b[0m\n\u001b[1;33m    h_A[i] = i * 0.5f;\u001b[0m\n\u001b[1;37m                   ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid decimal literal\n"
     ]
    }
   ],
   "source": [
    "#include <cuda_runtime.h>\n",
    "#include <iostream>\n",
    "\n",
    "#define N 1 << 20  // 1 million elements\n",
    "#define BLOCK_SIZE 256\n",
    "\n",
    "// Error checking macro\n",
    "#define CHECK(call) \\\n",
    "    { \\\n",
    "        const cudaError_t err = call; \\\n",
    "        if (err != cudaSuccess) { \\\n",
    "            std::cerr << \"CUDA error: \" << cudaGetErrorString(err) << \" at \" << __FILE__ << \":\" << __LINE__ << std::endl; \\\n",
    "            exit(EXIT_FAILURE); \\\n",
    "        } \\\n",
    "    }\n",
    "\n",
    "// Optimized kernel using grid-stride loop and __restrict__\n",
    "__global__ void vectorAdd(const float *__restrict__ A, const float *__restrict__ B, float *__restrict__ C, int n) {\n",
    "    int idx = blockIdx.x * blockDim.x + threadIdx.x;\n",
    "    \n",
    "    // Grid-stride loop for larger arrays\n",
    "    for (int i = idx; i < n; i += blockDim.x * gridDim.x) {\n",
    "        C[i] = A[i] + B[i];\n",
    "    }\n",
    "}\n",
    "\n",
    "int main() {\n",
    "    float *h_A, *h_B, *h_C;\n",
    "    float *d_A, *d_B, *d_C;\n",
    "\n",
    "    size_t bytes = N * sizeof(float);\n",
    "\n",
    "    // Pinned memory allocation for faster transfer\n",
    "    CHECK(cudaMallocHost(&h_A, bytes));\n",
    "    CHECK(cudaMallocHost(&h_B, bytes));\n",
    "    CHECK(cudaMallocHost(&h_C, bytes));\n",
    "\n",
    "    for (int i = 0; i < N; ++i) {\n",
    "        h_A[i] = i * 0.5f;\n",
    "        h_B[i] = i * 2.0f;\n",
    "    }\n",
    "\n",
    "    // Device memory\n",
    "    CHECK(cudaMalloc(&d_A, bytes));\n",
    "    CHECK(cudaMalloc(&d_B, bytes));\n",
    "    CHECK(cudaMalloc(&d_C, bytes));\n",
    "\n",
    "    // Async memory copy to overlap with computation (needs streams for full overlap)\n",
    "    CHECK(cudaMemcpy(d_A, h_A, bytes, cudaMemcpyHostToDevice));\n",
    "    CHECK(cudaMemcpy(d_B, h_B, bytes, cudaMemcpyHostToDevice));\n",
    "\n",
    "    int gridSize = (N + BLOCK_SIZE - 1) / BLOCK_SIZE;\n",
    "\n",
    "    // Launch optimized kernel\n",
    "    vectorAdd<<<gridSize, BLOCK_SIZE>>>(d_A, d_B, d_C, N);\n",
    "    CHECK(cudaGetLastError());\n",
    "\n",
    "    // Copy result back\n",
    "    CHECK(cudaMemcpy(h_C, d_C, bytes, cudaMemcpyDeviceToHost));\n",
    "\n",
    "    // Sample output check\n",
    "    std::cout << \"C[100] = \" << h_C[100] << std::endl;\n",
    "\n",
    "    // Cleanup\n",
    "    cudaFree(d_A);\n",
    "    cudaFree(d_B);\n",
    "    cudaFree(d_C);\n",
    "    cudaFreeHost(h_A);\n",
    "    cudaFreeHost(h_B);\n",
    "    cudaFreeHost(h_C);\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a392bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from efficientnet_pytorch import EfficientNet\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ca274d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "585ebbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "data_dir = r\"C:\\ELCDATASET\\Dataset\"\n",
    "train_dir = os.path.join(data_dir, 'Training')\n",
    "test_dir = os.path.join(data_dir, 'Test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5cf941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Transforms\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(300, scale=(0.6, 1.0)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(25),\n",
    "    transforms.ColorJitter(brightness=0.4, contrast=0.4, saturation=0.3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),\n",
    "    transforms.RandomErasing(p=0.5, scale=(0.02, 0.15))\n",
    "])\n",
    "\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((300, 300)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4398559",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Datasets\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=train_transforms)\n",
    "test_dataset = datasets.ImageFolder(test_dir, transform=test_transforms)\n",
    "class_names = train_dataset.classes\n",
    "num_classes = len(class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00fdec37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Handle class imbalance\n",
    "class_counts = np.bincount(train_dataset.targets)\n",
    "weights = 1. / class_counts[train_dataset.targets]\n",
    "sampler = WeightedRandomSampler(weights, len(weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "403db7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, sampler=sampler)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "042175c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained weights for efficientnet-b3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Model setup\n",
    "model = EfficientNet.from_pretrained('efficientnet-b3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e26a191a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Unfreeze selected layers\n",
    "for name, param in model.named_parameters():\n",
    "    if \"_blocks.30\" in name or \"_conv_head\" in name or \"_bn2\" in name:\n",
    "        param.requires_grad = True\n",
    "    else:\n",
    "        param.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d55bf678",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Replace classifier\n",
    "model._dropout = nn.Dropout(p=0.5)\n",
    "model._fc = nn.Sequential(\n",
    "    nn.Linear(model._fc.in_features, 128),\n",
    "    nn.BatchNorm1d(128),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.6),\n",
    "    nn.Linear(128, num_classes)\n",
    ")\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7471fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Loss, optimizer, scheduler\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-4)\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f3da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Training setup\n",
    "num_epochs =30  \n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "best_val_loss = float('inf')\n",
    "early_stop_patience = 5\n",
    "early_stop_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419ae7fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch [1/30] | LR: 0.000100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:  55%|█████▌    | 1973/3577 [2:34:26<1:34:53,  3.55s/it, acc=49.9, loss=1.64]c:\\Users\\91771\\anaconda3\\Lib\\site-packages\\PIL\\Image.py:1000: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  warnings.warn(\n",
      "Training:  94%|█████████▍| 3370/3577 [4:04:06<17:10,  4.98s/it, acc=58.3, loss=1.39]  "
     ]
    }
   ],
   "source": [
    "num_epochs =30  \n",
    "train_losses, val_losses = [], []\n",
    "train_accuracies, val_accuracies = [], []\n",
    "best_val_loss = float('inf')\n",
    "early_stop_patience = 5\n",
    "early_stop_counter = 0\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch [{epoch+1}/{num_epochs}] | LR: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0, 0, 0\n",
    "    loop = tqdm(train_loader, desc=\"Training\")\n",
    "\n",
    "    for images, labels in loop:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "        loop.set_postfix(loss=loss.item(), acc=100. * correct / total)\n",
    "\n",
    "    train_loss = total_loss / len(train_loader.dataset)\n",
    "    train_acc = 100. * correct / total\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_acc)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss, val_correct, val_total = 0, 0, 0\n",
    "    all_preds, all_labels = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            val_correct += (preds == labels).sum().item()\n",
    "            val_total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(test_loader.dataset)\n",
    "    val_acc = 100. * val_correct / val_total\n",
    "    val_losses.append(val_loss)\n",
    "    val_accuracies.append(val_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    print(f\"Train Acc: {train_acc:.2f}% | Val Acc: {val_acc:.2f}%\")\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "        print(\"  Saved best model\")\n",
    "        early_stop_counter = 0\n",
    "    else:\n",
    "        early_stop_counter += 1\n",
    "        if early_stop_counter >= early_stop_patience:\n",
    "            print(\" Early stopping triggered.\")\n",
    "            break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88770fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Final Classification Report\n",
    "print(\"\\n Classification Report:\")\n",
    "print(classification_report(all_labels, all_preds, target_names=class_names))\n",
    "\n",
    "# Accuracy & Loss plot\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_accuracies, label='Train Acc')\n",
    "plt.plot(val_accuracies, label='Val Acc')\n",
    "plt.legend(); plt.grid(); plt.title('Accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.legend(); \n",
    "plt.grid();\n",
    "plt.title('Loss')\n",
    "plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282ae600",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
